---
title: "Final Assignment"
author: "Helen Webley-Brown"
output: html_document
---
## Part 0: Set-Up

```{r setup, warning = FALSE, message = FALSE}

# load necessary packages and files
library(ggplot2)
library(dplyr)
library(tidyverse)
library(knitr)
library(rmarkdown)
library(ggpubr)
library(broom)

cog <- read.csv('hcp-cognitive.csv')
demo <- read.csv('hcp-demos.csv')
pers <- read.csv('hcp-personality.csv')

```

## Part 1: Data Wrangling

```{r data-wrangling, warning = FALSE, message = FALSE}

# deal with NAs in cog

cog$PMAT24_A_CR <- ifelse(is.na(cog$groupA.PMAT24_A_CR), cog$groupB.PMAT24_A_CR,cog$groupA.PMAT24_A_CR)

cog$ListSort_AgeAdj <- ifelse(is.na(cog$groupA.ListSort_AgeAdj), cog$groupB.ListSort_AgeAdj,cog$groupA.ListSort_AgeAdj)

cog$CardSort_AgeAdj <- ifelse(is.na(cog$groupA.CardSort_AgeAdj), cog$groupB.CardSort_AgeAdj,cog$groupA.CardSort_AgeAdj)

cog$ProcSpeed_AgeAdj <- ifelse(is.na(cog$groupA.ProcSpeed_AgeAdj), cog$groupB.ProcSpeed_AgeAdj,cog$groupA.ProcSpeed_AgeAdj)

# remove unnecessary columns from cog

cog <- cog %>% select(1,10:13)

# add ID to variable names in pers
prefix <- "ID"
pers$IDNumber <- paste(prefix, pers$IDNumber, sep = "")

# pivot pers  wider

pers <- pers %>% pivot_wider(names_from = Measure, values_from = Score)

# separate columns into 2 columns  

demo <- demo %>% 
  gather(key = "full_name", value = "value", starts_with(c("M_","F_"))) %>%
  separate(full_name, c("Gender", "Age"), sep="_(?=[^_]+$)") %>%
  drop_na(value) %>% 
  mutate_at(vars("Age"), ~str_replace(string = ., pattern = "\\.", replacement = "-")) %>% 
  select(1:3) %>%  
  mutate(Age=recode(Age,"36-"= "36+"))

# make dataframe
hcp <- data.frame(cog, demo, pers)

# remove unnecessary columns
hcp <- select(hcp, 1:5, 7,8,10:16)

# reorder columns
hcp <- hcp[c(1,6,7,4,2,5,3,8,9,10,14,11,13,12)]
head(hcp)
```

## Part 2: Describing Your Data


```{r describeData, warning = FALSE, message = FALSE}
# create 5 density plots on 5 variables
card <- ggplot(data = hcp, aes(x = CardSort_AgeAdj)) + 
  geom_density(alpha = 0.5, colour = "darkblue") + 
  theme_bw()

proc <- ggplot(data = hcp, aes(x = ProcSpeed_AgeAdj)) +
  geom_density(alpha = 0.5, colour = "pink") + 
  theme_bw() 

neoN <- ggplot(data = hcp, aes(x = NEOFAC_N)) + 
  geom_density(alpha = 0.5, colour = "darkgreen") +
  theme_bw()

life <- ggplot(data = hcp, aes(x = LifeSatisf_Unadj)) + 
  geom_density(alpha = 0.5, colour = "lightblue") + 
  theme_bw()

pmat <- ggplot(data = hcp, aes(x = PMAT24_A_CR)) +
  geom_density(alpha = 0.5, colour = "orange") +
  theme_bw()

# use ggarrange to arrange the 5 subplots on one figure

figure <- ggarrange(card, life, neoN, proc, pmat, nrow = 3, ncol = 2, labels = c(1,2,3,4,5))

# calculate  1 measure of central tendency and
# 1 measure of variability for life satisfaction

mean <- mean(hcp$LifeSatisf_Unadj)
range <- range(hcp$LifeSatisf_Unadj)

# add measures to bottom right of figure

annotate_figure(figure,
               top = text_grob("Visualizing The Human Connectome Project (HCP)", 
               color = "red", 
              face = "bold", size = 12),
               bottom = text_grob(paste0("life satisfaction mean = ", mean, 
                                         "\n life satisfaction range = ", range), 
                color = "blue",
          hjust = -.5, x = .5, face = "italic", size = 10),
               fig.lab = "Figure 1", fig.lab.face = "bold")

```

-

This figure shows the distribution of 5 variables: *1* - Change Card Sort Test, *2* - Life Satisfaction, *3* - Neuroticism, *4* - Processing Speed, and the *5* - Penn Matrix Test (left to right). *Subplots 1, 3, and 4* appear to be normally distributed, while *subplots 2 and 5* do not.

## Part 3: Statistical Modelling

*Hypothesis:*  Higher scores in meaning and purpose,agreeableness, and openness 
positively affects life satisfaction scores.
```{r regression, warning = FALSE, message = FALSE}

# standardise coefficients

Z.LifeSatisf_Unadj <- scale(hcp$LifeSatisf_Unadj)
Z.NEOFAC_O <- scale(hcp$NEOFAC_O)
Z.NEOFAC_A <- scale(hcp$NEOFAC_A)
Z.MeanPurp_Unadj <- scale(hcp$MeanPurp_Unadj)

# multiple linear regression

fit <- lm(Z.LifeSatisf_Unadj ~ Z.NEOFAC_O + Z.NEOFAC_A + Z.MeanPurp_Unadj, data=hcp)

summary(fit)

```

#### Interpret the findings

**Regression coefficients:**

*NEOFAC_O:* A 1 standard deviation change in NEOFAC_O predicts a -0.201467 standard deviation in life satisfaction, holding all other predictors constant.

*NEOFAC_A:* A 1 standard deviation change in NEOFAC_A predicts a 0.115603 standard deviation in life satisfaction, holding all other predictors constant.

*MeanPurp_Unadj:* A 1 standard deviation change in NEOFAC_A predicts a 0.512155 standard deviation in life satisfaction, holding all other predictors constant.

*Intercept:* When NEOFAC_O, NEOFAC_A, and MeanPurp_Unadj equal zero, life satisfaction is -0.005674.

**Omnibus test:** The omnibus test helps us know if the variance explained by our model is larger than the variance that is unexplained. The ratio of my regression to error is 18.61 on 3 and 95 degrees of freedom. As the p-value is much less than 0.05, we reject the null hypothesis. Hence there is a significant relationship between the variables in the multiple linear regression model.

**Model fit:** R squared is a measure of model fit as it provides the amount of variance in Y that is explained by X. We can intepret the multiple R-squared of 0.3701 to mean that 37% of the variance in life satisfaction scores is explained by meaning and purpose, agreeableness, and openness scores.

```{r residuals, warning = FALSE, message = FALSE}

modelInfo <- augment(fit)
head(modelInfo)

# store fitted and residual values in variables

fitted <- fitted(fit)
residuals <- residuals(fit)

# make dataframe with fitted and residual values

df <- data.frame(fitted, residuals)

ggplot(df, aes(x = fitted, y = residuals)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +
  geom_segment(aes(xend = fitted, yend = residuals), alpha = .2) + 
  geom_point() +
  geom_point(aes(y = residuals), shape = 1) +
  theme_bw() + ggtitle("Residuals vs. Fitted Values")

```

## Part 4: Simulating Power

```{r, warning = FALSE, message = FALSE}

# set seed

set.seed(4175)

# create empty variables to store loop results

Sim.LifeSatisf_Unadj <- NULL
Sim.NEOFAC_O <- NULL
Sim.NEOFAC_A <- NULL
Sim.MeanPurp_Unadj <- NULL
regress <- NULL
regress2 <- NULL
sig <- NULL

# for loop that simulates  data

for (i in 1:5000) {
  
  # generate dataset
      
Sim.LifeSatisf_Unadj <- runif(n = 100, min = 34.2, max = 74.6)
Sim.NEOFAC_O <- runif(n = 100, min = 15, max = 44)
Sim.NEOFAC_A <- rnorm(n = 100, mean = 33.61616, sd = 6.018182)
Sim.MeanPurp_Unadj <- rnorm(n = 100, mean = 53.166, sd = 9.550559)

    # run and store regression
    
     regress <-  lm(Sim.LifeSatisf_Unadj ~ Sim.NEOFAC_O + Sim.NEOFAC_A + Sim.MeanPurp_Unadj, data=hcp)
 
     regress2 <- tidy(regress)

          # store if result is significant or not

   sig[i] <- regress2$p.value <= 0.05
      
}

# print out the statistical power 
power<- mean(sig, na.rm = TRUE)
print(power)

```
Statistical power is often shown by the probability statement of 1 - beta and relates to the challenge of controlling Type II errors, which depend on several factors. The power for the regression I ran is 0.999... This can be interpreted as there being a 99.9% probability of correctly rejecting a false null hypothesis...

One way to think about power is as the probability of avoiding a Type II error, meaning correctly rejecting a null hypothesis when it is false. Some factors that affect power include: significance level (alpha), sample size, and effect size. 

A worrying thing about  research is that many studies suffer from powers lower than the preferred 0.8, resulting in a reproducibility dilemma. Increasing sample size (N) is a popular method to increase power and avoid failing signal detection.

